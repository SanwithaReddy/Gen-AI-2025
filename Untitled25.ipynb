{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmiO7Te2MBhTO2sfJT8dCP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanwithaReddy/Gen-AI-2025/blob/main/Untitled25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "LxIXgsMlQh36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import joblib\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adagrad\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "file_path = \"diabetes.xls\"\n",
        "data = pd.read_excel(file_path)\n",
        "print(\"Dataset Info:\\n\", data.info())\n",
        "print(\"\\nMissing Values:\\n\", data.isnull().sum())\n",
        "\n",
        "data.fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(12, activation=\"swish\", input_shape=(X_train.shape[1],)),\n",
        "    Dense(25, activation=\"swish\"),\n",
        "    Dense(15, activation=\"swish\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adagrad(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=300, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=[\"Non-Diabetic\", \"Diabetic\"])\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(report)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non-Diabetic\", \"Diabetic\"],\n",
        "            yticklabels=[\"Non-Diabetic\", \"Diabetic\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "model_filename = \"diabetes_ann_model.keras\"\n",
        "\n",
        "if os.path.exists(model_filename):\n",
        "    os.remove(model_filename)\n",
        "\n",
        "model.save(model_filename)\n",
        "print(\"Model saved successfully!\")\n",
        "\n",
        "def load_trained_model():\n",
        "    return load_model(\"diabetes_ann_model.keras\"), joblib.load(\"scaler.pkl\")\n",
        "\n",
        "def predict_diabetes(input_data):\n",
        "    model, scaler = load_trained_model()\n",
        "    input_array = np.array(input_data).reshape(1, -1)\n",
        "    input_scaled = scaler.transform(input_array)\n",
        "    prediction = model.predict(input_scaled)\n",
        "    return \"Diabetic\" if prediction > 0.5 else \"Non-Diabetic\"\n",
        "\n",
        "sample_input = [6, 148, 72, 35, 0, 33.6, 0.627, 50]\n",
        "result = predict_diabetes(sample_input)\n",
        "print(f\"Prediction: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HBN3wRO1UIQm",
        "outputId": "98f6d6f7-e0d6-4f35-d49e-0c05875428ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 768 entries, 0 to 767\n",
            "Data columns (total 9 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Pregnancies               768 non-null    int64  \n",
            " 1   Glucose                   768 non-null    int64  \n",
            " 2   BloodPressure             768 non-null    int64  \n",
            " 3   SkinThickness             768 non-null    int64  \n",
            " 4   Insulin                   768 non-null    int64  \n",
            " 5   BMI                       768 non-null    float64\n",
            " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
            " 7   Age                       768 non-null    int64  \n",
            " 8   Outcome                   768 non-null    int64  \n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 54.1 KB\n",
            "Dataset Info:\n",
            " None\n",
            "\n",
            "Missing Values:\n",
            " Pregnancies                 0\n",
            "Glucose                     0\n",
            "BloodPressure               0\n",
            "SkinThickness               0\n",
            "Insulin                     0\n",
            "BMI                         0\n",
            "DiabetesPedigreeFunction    0\n",
            "Age                         0\n",
            "Outcome                     0\n",
            "dtype: int64\n",
            "Epoch 1/300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.4564 - loss: 0.7018 - val_accuracy: 0.4675 - val_loss: 0.7054\n",
            "Epoch 2/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4734 - loss: 0.6980 - val_accuracy: 0.5130 - val_loss: 0.7039\n",
            "Epoch 3/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4894 - loss: 0.6972 - val_accuracy: 0.5130 - val_loss: 0.7025\n",
            "Epoch 4/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5498 - loss: 0.6944 - val_accuracy: 0.5325 - val_loss: 0.7014\n",
            "Epoch 5/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5540 - loss: 0.6955 - val_accuracy: 0.5195 - val_loss: 0.7003\n",
            "Epoch 6/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5479 - loss: 0.6958 - val_accuracy: 0.5455 - val_loss: 0.6993\n",
            "Epoch 7/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5472 - loss: 0.6936 - val_accuracy: 0.5390 - val_loss: 0.6984\n",
            "Epoch 8/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5988 - loss: 0.6906 - val_accuracy: 0.5519 - val_loss: 0.6975\n",
            "Epoch 9/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5851 - loss: 0.6890 - val_accuracy: 0.5519 - val_loss: 0.6966\n",
            "Epoch 10/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5905 - loss: 0.6853 - val_accuracy: 0.5584 - val_loss: 0.6958\n",
            "Epoch 11/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5709 - loss: 0.6928 - val_accuracy: 0.5519 - val_loss: 0.6950\n",
            "Epoch 12/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6003 - loss: 0.6856 - val_accuracy: 0.5584 - val_loss: 0.6943\n",
            "Epoch 13/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5945 - loss: 0.6909 - val_accuracy: 0.5584 - val_loss: 0.6935\n",
            "Epoch 14/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6307 - loss: 0.6842 - val_accuracy: 0.5584 - val_loss: 0.6928\n",
            "Epoch 15/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5996 - loss: 0.6858 - val_accuracy: 0.5714 - val_loss: 0.6922\n",
            "Epoch 16/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6423 - loss: 0.6815 - val_accuracy: 0.5779 - val_loss: 0.6915\n",
            "Epoch 17/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6100 - loss: 0.6876 - val_accuracy: 0.5779 - val_loss: 0.6909\n",
            "Epoch 18/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6334 - loss: 0.6805 - val_accuracy: 0.5779 - val_loss: 0.6902\n",
            "Epoch 19/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6193 - loss: 0.6814 - val_accuracy: 0.5779 - val_loss: 0.6896\n",
            "Epoch 20/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6137 - loss: 0.6835 - val_accuracy: 0.5844 - val_loss: 0.6890\n",
            "Epoch 21/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6245 - loss: 0.6837 - val_accuracy: 0.5909 - val_loss: 0.6884\n",
            "Epoch 22/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6237 - loss: 0.6809 - val_accuracy: 0.6039 - val_loss: 0.6878\n",
            "Epoch 23/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6685 - loss: 0.6792 - val_accuracy: 0.6169 - val_loss: 0.6872\n",
            "Epoch 24/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6515 - loss: 0.6772 - val_accuracy: 0.6299 - val_loss: 0.6867\n",
            "Epoch 25/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6610 - loss: 0.6788 - val_accuracy: 0.6234 - val_loss: 0.6862\n",
            "Epoch 26/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6737 - loss: 0.6758 - val_accuracy: 0.6234 - val_loss: 0.6856\n",
            "Epoch 27/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6654 - loss: 0.6768 - val_accuracy: 0.6234 - val_loss: 0.6851\n",
            "Epoch 28/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6716 - loss: 0.6751 - val_accuracy: 0.6234 - val_loss: 0.6845\n",
            "Epoch 29/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6592 - loss: 0.6738 - val_accuracy: 0.6299 - val_loss: 0.6840\n",
            "Epoch 30/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6575 - loss: 0.6756 - val_accuracy: 0.6299 - val_loss: 0.6835\n",
            "Epoch 31/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6805 - loss: 0.6697 - val_accuracy: 0.6364 - val_loss: 0.6830\n",
            "Epoch 32/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6396 - loss: 0.6761 - val_accuracy: 0.6299 - val_loss: 0.6825\n",
            "Epoch 33/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6640 - loss: 0.6711 - val_accuracy: 0.6364 - val_loss: 0.6820\n",
            "Epoch 34/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6704 - loss: 0.6690 - val_accuracy: 0.6429 - val_loss: 0.6815\n",
            "Epoch 35/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6679 - loss: 0.6688 - val_accuracy: 0.6429 - val_loss: 0.6810\n",
            "Epoch 36/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6668 - loss: 0.6736 - val_accuracy: 0.6429 - val_loss: 0.6805\n",
            "Epoch 37/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6693 - loss: 0.6713 - val_accuracy: 0.6429 - val_loss: 0.6800\n",
            "Epoch 38/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6638 - loss: 0.6676 - val_accuracy: 0.6429 - val_loss: 0.6795\n",
            "Epoch 39/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6802 - loss: 0.6698 - val_accuracy: 0.6494 - val_loss: 0.6791\n",
            "Epoch 40/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6645 - loss: 0.6684 - val_accuracy: 0.6494 - val_loss: 0.6786\n",
            "Epoch 41/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6601 - loss: 0.6706 - val_accuracy: 0.6494 - val_loss: 0.6781\n",
            "Epoch 42/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6400 - loss: 0.6742 - val_accuracy: 0.6558 - val_loss: 0.6776\n",
            "Epoch 43/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6678 - loss: 0.6642 - val_accuracy: 0.6558 - val_loss: 0.6772\n",
            "Epoch 44/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6959 - loss: 0.6611 - val_accuracy: 0.6558 - val_loss: 0.6767\n",
            "Epoch 45/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6689 - loss: 0.6661 - val_accuracy: 0.6494 - val_loss: 0.6763\n",
            "Epoch 46/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6796 - loss: 0.6647 - val_accuracy: 0.6494 - val_loss: 0.6758\n",
            "Epoch 47/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6890 - loss: 0.6628 - val_accuracy: 0.6494 - val_loss: 0.6754\n",
            "Epoch 48/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6469 - loss: 0.6645 - val_accuracy: 0.6494 - val_loss: 0.6749\n",
            "Epoch 49/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6587 - loss: 0.6670 - val_accuracy: 0.6494 - val_loss: 0.6745\n",
            "Epoch 50/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6439 - loss: 0.6676 - val_accuracy: 0.6494 - val_loss: 0.6740\n",
            "Epoch 51/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6478 - loss: 0.6663 - val_accuracy: 0.6494 - val_loss: 0.6736\n",
            "Epoch 52/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6562 - loss: 0.6637 - val_accuracy: 0.6494 - val_loss: 0.6731\n",
            "Epoch 53/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6691 - loss: 0.6587 - val_accuracy: 0.6494 - val_loss: 0.6727\n",
            "Epoch 54/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6332 - loss: 0.6696 - val_accuracy: 0.6494 - val_loss: 0.6722\n",
            "Epoch 55/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6558 - loss: 0.6621 - val_accuracy: 0.6494 - val_loss: 0.6718\n",
            "Epoch 56/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6435 - loss: 0.6652 - val_accuracy: 0.6494 - val_loss: 0.6714\n",
            "Epoch 57/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6436 - loss: 0.6624 - val_accuracy: 0.6494 - val_loss: 0.6709\n",
            "Epoch 58/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6553 - loss: 0.6581 - val_accuracy: 0.6494 - val_loss: 0.6705\n",
            "Epoch 59/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6562 - loss: 0.6581 - val_accuracy: 0.6429 - val_loss: 0.6701\n",
            "Epoch 60/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6744 - loss: 0.6561 - val_accuracy: 0.6429 - val_loss: 0.6696\n",
            "Epoch 61/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6800 - loss: 0.6536 - val_accuracy: 0.6429 - val_loss: 0.6692\n",
            "Epoch 62/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6490 - loss: 0.6571 - val_accuracy: 0.6429 - val_loss: 0.6687\n",
            "Epoch 63/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6477 - loss: 0.6602 - val_accuracy: 0.6429 - val_loss: 0.6683\n",
            "Epoch 64/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6508 - loss: 0.6586 - val_accuracy: 0.6429 - val_loss: 0.6679\n",
            "Epoch 65/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6624 - loss: 0.6558 - val_accuracy: 0.6429 - val_loss: 0.6674\n",
            "Epoch 66/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6601 - loss: 0.6518 - val_accuracy: 0.6429 - val_loss: 0.6670\n",
            "Epoch 67/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6455 - loss: 0.6588 - val_accuracy: 0.6429 - val_loss: 0.6666\n",
            "Epoch 68/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6560 - loss: 0.6556 - val_accuracy: 0.6429 - val_loss: 0.6662\n",
            "Epoch 69/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6657 - loss: 0.6552 - val_accuracy: 0.6429 - val_loss: 0.6657\n",
            "Epoch 70/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6160 - loss: 0.6572 - val_accuracy: 0.6429 - val_loss: 0.6653\n",
            "Epoch 71/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6511 - loss: 0.6525 - val_accuracy: 0.6429 - val_loss: 0.6649\n",
            "Epoch 72/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6536 - loss: 0.6539 - val_accuracy: 0.6429 - val_loss: 0.6644\n",
            "Epoch 73/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6565 - loss: 0.6528 - val_accuracy: 0.6429 - val_loss: 0.6640\n",
            "Epoch 74/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6559 - loss: 0.6501 - val_accuracy: 0.6429 - val_loss: 0.6636\n",
            "Epoch 75/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6552 - loss: 0.6527 - val_accuracy: 0.6429 - val_loss: 0.6631\n",
            "Epoch 76/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6774 - loss: 0.6439 - val_accuracy: 0.6429 - val_loss: 0.6627\n",
            "Epoch 77/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6581 - loss: 0.6508 - val_accuracy: 0.6429 - val_loss: 0.6623\n",
            "Epoch 78/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6669 - loss: 0.6451 - val_accuracy: 0.6429 - val_loss: 0.6618\n",
            "Epoch 79/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6569 - loss: 0.6515 - val_accuracy: 0.6429 - val_loss: 0.6614\n",
            "Epoch 80/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6627 - loss: 0.6466 - val_accuracy: 0.6429 - val_loss: 0.6610\n",
            "Epoch 81/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6573 - loss: 0.6496 - val_accuracy: 0.6429 - val_loss: 0.6605\n",
            "Epoch 82/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6426 - loss: 0.6512 - val_accuracy: 0.6494 - val_loss: 0.6601\n",
            "Epoch 83/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6825 - loss: 0.6424 - val_accuracy: 0.6494 - val_loss: 0.6597\n",
            "Epoch 84/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6263 - loss: 0.6527 - val_accuracy: 0.6494 - val_loss: 0.6592\n",
            "Epoch 85/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6459 - loss: 0.6495 - val_accuracy: 0.6494 - val_loss: 0.6588\n",
            "Epoch 86/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6404 - loss: 0.6538 - val_accuracy: 0.6494 - val_loss: 0.6584\n",
            "Epoch 87/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6573 - loss: 0.6497 - val_accuracy: 0.6494 - val_loss: 0.6579\n",
            "Epoch 88/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6587 - loss: 0.6419 - val_accuracy: 0.6494 - val_loss: 0.6575\n",
            "Epoch 89/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6507 - loss: 0.6472 - val_accuracy: 0.6494 - val_loss: 0.6571\n",
            "Epoch 90/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6478 - loss: 0.6412 - val_accuracy: 0.6494 - val_loss: 0.6566\n",
            "Epoch 91/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6674 - loss: 0.6454 - val_accuracy: 0.6494 - val_loss: 0.6562\n",
            "Epoch 92/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6486 - loss: 0.6441 - val_accuracy: 0.6494 - val_loss: 0.6558\n",
            "Epoch 93/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6545 - loss: 0.6434 - val_accuracy: 0.6494 - val_loss: 0.6553\n",
            "Epoch 94/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6568 - loss: 0.6420 - val_accuracy: 0.6494 - val_loss: 0.6549\n",
            "Epoch 95/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6623 - loss: 0.6369 - val_accuracy: 0.6494 - val_loss: 0.6545\n",
            "Epoch 96/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6909 - loss: 0.6312 - val_accuracy: 0.6494 - val_loss: 0.6540\n",
            "Epoch 97/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6471 - loss: 0.6433 - val_accuracy: 0.6494 - val_loss: 0.6536\n",
            "Epoch 98/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6399 - loss: 0.6420 - val_accuracy: 0.6494 - val_loss: 0.6532\n",
            "Epoch 99/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6340 - loss: 0.6429 - val_accuracy: 0.6494 - val_loss: 0.6527\n",
            "Epoch 100/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6343 - loss: 0.6442 - val_accuracy: 0.6494 - val_loss: 0.6523\n",
            "Epoch 101/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6497 - loss: 0.6380 - val_accuracy: 0.6494 - val_loss: 0.6519\n",
            "Epoch 102/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6907 - loss: 0.6271 - val_accuracy: 0.6494 - val_loss: 0.6514\n",
            "Epoch 103/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6395 - loss: 0.6421 - val_accuracy: 0.6494 - val_loss: 0.6510\n",
            "Epoch 104/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6405 - loss: 0.6449 - val_accuracy: 0.6494 - val_loss: 0.6505\n",
            "Epoch 105/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6477 - loss: 0.6429 - val_accuracy: 0.6494 - val_loss: 0.6501\n",
            "Epoch 106/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6797 - loss: 0.6330 - val_accuracy: 0.6494 - val_loss: 0.6496\n",
            "Epoch 107/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6736 - loss: 0.6291 - val_accuracy: 0.6494 - val_loss: 0.6492\n",
            "Epoch 108/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6607 - loss: 0.6299 - val_accuracy: 0.6494 - val_loss: 0.6487\n",
            "Epoch 109/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6655 - loss: 0.6298 - val_accuracy: 0.6494 - val_loss: 0.6483\n",
            "Epoch 110/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6615 - loss: 0.6323 - val_accuracy: 0.6494 - val_loss: 0.6478\n",
            "Epoch 111/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6473 - loss: 0.6339 - val_accuracy: 0.6494 - val_loss: 0.6474\n",
            "Epoch 112/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6630 - loss: 0.6314 - val_accuracy: 0.6494 - val_loss: 0.6470\n",
            "Epoch 113/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6870 - loss: 0.6239 - val_accuracy: 0.6494 - val_loss: 0.6465\n",
            "Epoch 114/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6552 - loss: 0.6300 - val_accuracy: 0.6494 - val_loss: 0.6461\n",
            "Epoch 115/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6559 - loss: 0.6292 - val_accuracy: 0.6494 - val_loss: 0.6456\n",
            "Epoch 116/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6350 - loss: 0.6358 - val_accuracy: 0.6494 - val_loss: 0.6452\n",
            "Epoch 117/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6450 - loss: 0.6354 - val_accuracy: 0.6494 - val_loss: 0.6447\n",
            "Epoch 118/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6616 - loss: 0.6255 - val_accuracy: 0.6494 - val_loss: 0.6443\n",
            "Epoch 119/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6752 - loss: 0.6188 - val_accuracy: 0.6494 - val_loss: 0.6438\n",
            "Epoch 120/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6757 - loss: 0.6223 - val_accuracy: 0.6494 - val_loss: 0.6434\n",
            "Epoch 121/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6299 - loss: 0.6394 - val_accuracy: 0.6494 - val_loss: 0.6429\n",
            "Epoch 122/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6539 - loss: 0.6298 - val_accuracy: 0.6494 - val_loss: 0.6425\n",
            "Epoch 123/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6566 - loss: 0.6262 - val_accuracy: 0.6494 - val_loss: 0.6420\n",
            "Epoch 124/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6672 - loss: 0.6204 - val_accuracy: 0.6494 - val_loss: 0.6416\n",
            "Epoch 125/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6408 - loss: 0.6279 - val_accuracy: 0.6494 - val_loss: 0.6411\n",
            "Epoch 126/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6652 - loss: 0.6225 - val_accuracy: 0.6494 - val_loss: 0.6407\n",
            "Epoch 127/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6681 - loss: 0.6218 - val_accuracy: 0.6494 - val_loss: 0.6402\n",
            "Epoch 128/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6522 - loss: 0.6286 - val_accuracy: 0.6494 - val_loss: 0.6398\n",
            "Epoch 129/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6676 - loss: 0.6257 - val_accuracy: 0.6494 - val_loss: 0.6393\n",
            "Epoch 130/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6403 - loss: 0.6322 - val_accuracy: 0.6494 - val_loss: 0.6389\n",
            "Epoch 131/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6542 - loss: 0.6296 - val_accuracy: 0.6494 - val_loss: 0.6384\n",
            "Epoch 132/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6320 - loss: 0.6297 - val_accuracy: 0.6494 - val_loss: 0.6380\n",
            "Epoch 133/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6621 - loss: 0.6211 - val_accuracy: 0.6494 - val_loss: 0.6375\n",
            "Epoch 134/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6660 - loss: 0.6181 - val_accuracy: 0.6494 - val_loss: 0.6370\n",
            "Epoch 135/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6479 - loss: 0.6272 - val_accuracy: 0.6494 - val_loss: 0.6366\n",
            "Epoch 136/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6391 - loss: 0.6274 - val_accuracy: 0.6494 - val_loss: 0.6361\n",
            "Epoch 137/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6255 - loss: 0.6287 - val_accuracy: 0.6494 - val_loss: 0.6357\n",
            "Epoch 138/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6612 - loss: 0.6232 - val_accuracy: 0.6494 - val_loss: 0.6352\n",
            "Epoch 139/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6732 - loss: 0.6132 - val_accuracy: 0.6494 - val_loss: 0.6348\n",
            "Epoch 140/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6632 - loss: 0.6196 - val_accuracy: 0.6494 - val_loss: 0.6343\n",
            "Epoch 141/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6991 - loss: 0.6069 - val_accuracy: 0.6494 - val_loss: 0.6339\n",
            "Epoch 142/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6445 - loss: 0.6250 - val_accuracy: 0.6494 - val_loss: 0.6334\n",
            "Epoch 143/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6315 - loss: 0.6232 - val_accuracy: 0.6494 - val_loss: 0.6329\n",
            "Epoch 144/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6481 - loss: 0.6162 - val_accuracy: 0.6494 - val_loss: 0.6325\n",
            "Epoch 145/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6521 - loss: 0.6235 - val_accuracy: 0.6494 - val_loss: 0.6320\n",
            "Epoch 146/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6494 - loss: 0.6215 - val_accuracy: 0.6494 - val_loss: 0.6316\n",
            "Epoch 147/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6442 - loss: 0.6177 - val_accuracy: 0.6494 - val_loss: 0.6311\n",
            "Epoch 148/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6500 - loss: 0.6179 - val_accuracy: 0.6494 - val_loss: 0.6307\n",
            "Epoch 149/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6745 - loss: 0.6069 - val_accuracy: 0.6494 - val_loss: 0.6302\n",
            "Epoch 150/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6729 - loss: 0.6109 - val_accuracy: 0.6494 - val_loss: 0.6298\n",
            "Epoch 151/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6563 - loss: 0.6215 - val_accuracy: 0.6494 - val_loss: 0.6293\n",
            "Epoch 152/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6634 - loss: 0.6149 - val_accuracy: 0.6494 - val_loss: 0.6289\n",
            "Epoch 153/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6654 - loss: 0.6129 - val_accuracy: 0.6494 - val_loss: 0.6284\n",
            "Epoch 154/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6521 - loss: 0.6145 - val_accuracy: 0.6494 - val_loss: 0.6280\n",
            "Epoch 155/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6169 - loss: 0.6292 - val_accuracy: 0.6494 - val_loss: 0.6275\n",
            "Epoch 156/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6906 - loss: 0.5932 - val_accuracy: 0.6494 - val_loss: 0.6271\n",
            "Epoch 157/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6741 - loss: 0.6060 - val_accuracy: 0.6494 - val_loss: 0.6266\n",
            "Epoch 158/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6532 - loss: 0.6123 - val_accuracy: 0.6494 - val_loss: 0.6262\n",
            "Epoch 159/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6550 - loss: 0.6124 - val_accuracy: 0.6494 - val_loss: 0.6257\n",
            "Epoch 160/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6606 - loss: 0.6026 - val_accuracy: 0.6494 - val_loss: 0.6252\n",
            "Epoch 161/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6530 - loss: 0.6107 - val_accuracy: 0.6494 - val_loss: 0.6248\n",
            "Epoch 162/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6625 - loss: 0.6128 - val_accuracy: 0.6494 - val_loss: 0.6243\n",
            "Epoch 163/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6664 - loss: 0.6113 - val_accuracy: 0.6494 - val_loss: 0.6239\n",
            "Epoch 164/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6475 - loss: 0.6137 - val_accuracy: 0.6494 - val_loss: 0.6234\n",
            "Epoch 165/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6889 - loss: 0.5909 - val_accuracy: 0.6494 - val_loss: 0.6230\n",
            "Epoch 166/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6579 - loss: 0.6123 - val_accuracy: 0.6494 - val_loss: 0.6225\n",
            "Epoch 167/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6835 - loss: 0.6017 - val_accuracy: 0.6494 - val_loss: 0.6221\n",
            "Epoch 168/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6400 - loss: 0.6251 - val_accuracy: 0.6494 - val_loss: 0.6216\n",
            "Epoch 169/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6607 - loss: 0.6142 - val_accuracy: 0.6494 - val_loss: 0.6212\n",
            "Epoch 170/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6599 - loss: 0.6095 - val_accuracy: 0.6494 - val_loss: 0.6207\n",
            "Epoch 171/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6553 - loss: 0.6029 - val_accuracy: 0.6494 - val_loss: 0.6203\n",
            "Epoch 172/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6825 - loss: 0.5928 - val_accuracy: 0.6494 - val_loss: 0.6198\n",
            "Epoch 173/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6857 - loss: 0.5938 - val_accuracy: 0.6494 - val_loss: 0.6194\n",
            "Epoch 174/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6842 - loss: 0.5863 - val_accuracy: 0.6494 - val_loss: 0.6189\n",
            "Epoch 175/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6514 - loss: 0.6073 - val_accuracy: 0.6494 - val_loss: 0.6185\n",
            "Epoch 176/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7087 - loss: 0.5729 - val_accuracy: 0.6494 - val_loss: 0.6180\n",
            "Epoch 177/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6525 - loss: 0.6175 - val_accuracy: 0.6494 - val_loss: 0.6176\n",
            "Epoch 178/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6572 - loss: 0.5994 - val_accuracy: 0.6494 - val_loss: 0.6171\n",
            "Epoch 179/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6966 - loss: 0.5897 - val_accuracy: 0.6494 - val_loss: 0.6167\n",
            "Epoch 180/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6714 - loss: 0.6009 - val_accuracy: 0.6494 - val_loss: 0.6162\n",
            "Epoch 181/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6750 - loss: 0.5938 - val_accuracy: 0.6494 - val_loss: 0.6158\n",
            "Epoch 182/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6492 - loss: 0.5911 - val_accuracy: 0.6494 - val_loss: 0.6153\n",
            "Epoch 183/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6513 - loss: 0.6049 - val_accuracy: 0.6494 - val_loss: 0.6149\n",
            "Epoch 184/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6569 - loss: 0.5998 - val_accuracy: 0.6494 - val_loss: 0.6144\n",
            "Epoch 185/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6814 - loss: 0.5918 - val_accuracy: 0.6558 - val_loss: 0.6140\n",
            "Epoch 186/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6436 - loss: 0.5969 - val_accuracy: 0.6558 - val_loss: 0.6135\n",
            "Epoch 187/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6578 - loss: 0.5898 - val_accuracy: 0.6558 - val_loss: 0.6131\n",
            "Epoch 188/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6653 - loss: 0.5967 - val_accuracy: 0.6558 - val_loss: 0.6126\n",
            "Epoch 189/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6553 - loss: 0.5941 - val_accuracy: 0.6558 - val_loss: 0.6122\n",
            "Epoch 190/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6529 - loss: 0.6029 - val_accuracy: 0.6558 - val_loss: 0.6118\n",
            "Epoch 191/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6515 - loss: 0.5973 - val_accuracy: 0.6558 - val_loss: 0.6113\n",
            "Epoch 192/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6661 - loss: 0.5919 - val_accuracy: 0.6558 - val_loss: 0.6109\n",
            "Epoch 193/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6743 - loss: 0.5838 - val_accuracy: 0.6558 - val_loss: 0.6105\n",
            "Epoch 194/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6599 - loss: 0.5977 - val_accuracy: 0.6558 - val_loss: 0.6100\n",
            "Epoch 195/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6570 - loss: 0.5972 - val_accuracy: 0.6558 - val_loss: 0.6096\n",
            "Epoch 196/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6767 - loss: 0.5807 - val_accuracy: 0.6558 - val_loss: 0.6091\n",
            "Epoch 197/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6342 - loss: 0.6050 - val_accuracy: 0.6558 - val_loss: 0.6087\n",
            "Epoch 198/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6798 - loss: 0.5866 - val_accuracy: 0.6558 - val_loss: 0.6083\n",
            "Epoch 199/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6696 - loss: 0.5912 - val_accuracy: 0.6558 - val_loss: 0.6078\n",
            "Epoch 200/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6593 - loss: 0.5853 - val_accuracy: 0.6558 - val_loss: 0.6074\n",
            "Epoch 201/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6707 - loss: 0.5947 - val_accuracy: 0.6558 - val_loss: 0.6069\n",
            "Epoch 202/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6660 - loss: 0.5780 - val_accuracy: 0.6558 - val_loss: 0.6065\n",
            "Epoch 203/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6471 - loss: 0.5929 - val_accuracy: 0.6558 - val_loss: 0.6061\n",
            "Epoch 204/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7034 - loss: 0.5795 - val_accuracy: 0.6558 - val_loss: 0.6056\n",
            "Epoch 205/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6651 - loss: 0.5879 - val_accuracy: 0.6558 - val_loss: 0.6052\n",
            "Epoch 206/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6616 - loss: 0.5950 - val_accuracy: 0.6558 - val_loss: 0.6048\n",
            "Epoch 207/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6830 - loss: 0.5668 - val_accuracy: 0.6623 - val_loss: 0.6043\n",
            "Epoch 208/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6976 - loss: 0.5703 - val_accuracy: 0.6623 - val_loss: 0.6039\n",
            "Epoch 209/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7007 - loss: 0.5830 - val_accuracy: 0.6623 - val_loss: 0.6034\n",
            "Epoch 210/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6678 - loss: 0.5903 - val_accuracy: 0.6623 - val_loss: 0.6030\n",
            "Epoch 211/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6628 - loss: 0.5936 - val_accuracy: 0.6623 - val_loss: 0.6026\n",
            "Epoch 212/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6779 - loss: 0.5846 - val_accuracy: 0.6623 - val_loss: 0.6021\n",
            "Epoch 213/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6624 - loss: 0.5992 - val_accuracy: 0.6623 - val_loss: 0.6017\n",
            "Epoch 214/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6567 - loss: 0.5843 - val_accuracy: 0.6623 - val_loss: 0.6013\n",
            "Epoch 215/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6767 - loss: 0.5964 - val_accuracy: 0.6623 - val_loss: 0.6009\n",
            "Epoch 216/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6436 - loss: 0.6150 - val_accuracy: 0.6623 - val_loss: 0.6004\n",
            "Epoch 217/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6738 - loss: 0.5788 - val_accuracy: 0.6558 - val_loss: 0.6000\n",
            "Epoch 218/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6659 - loss: 0.5886 - val_accuracy: 0.6558 - val_loss: 0.5996\n",
            "Epoch 219/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6565 - loss: 0.5984 - val_accuracy: 0.6558 - val_loss: 0.5992\n",
            "Epoch 220/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6676 - loss: 0.5796 - val_accuracy: 0.6558 - val_loss: 0.5988\n",
            "Epoch 221/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6675 - loss: 0.5734 - val_accuracy: 0.6558 - val_loss: 0.5984\n",
            "Epoch 222/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6799 - loss: 0.5807 - val_accuracy: 0.6558 - val_loss: 0.5980\n",
            "Epoch 223/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6798 - loss: 0.5821 - val_accuracy: 0.6558 - val_loss: 0.5975\n",
            "Epoch 224/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6759 - loss: 0.5762 - val_accuracy: 0.6558 - val_loss: 0.5971\n",
            "Epoch 225/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6827 - loss: 0.5763 - val_accuracy: 0.6558 - val_loss: 0.5967\n",
            "Epoch 226/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6739 - loss: 0.5778 - val_accuracy: 0.6558 - val_loss: 0.5963\n",
            "Epoch 227/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6870 - loss: 0.5788 - val_accuracy: 0.6494 - val_loss: 0.5959\n",
            "Epoch 228/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7071 - loss: 0.5544 - val_accuracy: 0.6494 - val_loss: 0.5955\n",
            "Epoch 229/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6916 - loss: 0.5664 - val_accuracy: 0.6494 - val_loss: 0.5951\n",
            "Epoch 230/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6950 - loss: 0.5702 - val_accuracy: 0.6494 - val_loss: 0.5947\n",
            "Epoch 231/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7169 - loss: 0.5705 - val_accuracy: 0.6494 - val_loss: 0.5943\n",
            "Epoch 232/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7161 - loss: 0.5620 - val_accuracy: 0.6494 - val_loss: 0.5938\n",
            "Epoch 233/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6512 - loss: 0.5895 - val_accuracy: 0.6494 - val_loss: 0.5934\n",
            "Epoch 234/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6549 - loss: 0.5835 - val_accuracy: 0.6494 - val_loss: 0.5930\n",
            "Epoch 235/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6963 - loss: 0.5718 - val_accuracy: 0.6494 - val_loss: 0.5926\n",
            "Epoch 236/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6990 - loss: 0.5698 - val_accuracy: 0.6494 - val_loss: 0.5922\n",
            "Epoch 237/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6886 - loss: 0.5848 - val_accuracy: 0.6494 - val_loss: 0.5918\n",
            "Epoch 238/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6895 - loss: 0.5736 - val_accuracy: 0.6494 - val_loss: 0.5914\n",
            "Epoch 239/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6711 - loss: 0.5797 - val_accuracy: 0.6494 - val_loss: 0.5910\n",
            "Epoch 240/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6740 - loss: 0.5836 - val_accuracy: 0.6494 - val_loss: 0.5906\n",
            "Epoch 241/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6548 - loss: 0.5827 - val_accuracy: 0.6494 - val_loss: 0.5902\n",
            "Epoch 242/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6934 - loss: 0.5637 - val_accuracy: 0.6494 - val_loss: 0.5898\n",
            "Epoch 243/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7023 - loss: 0.5606 - val_accuracy: 0.6494 - val_loss: 0.5894\n",
            "Epoch 244/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6822 - loss: 0.5782 - val_accuracy: 0.6494 - val_loss: 0.5891\n",
            "Epoch 245/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6775 - loss: 0.5779 - val_accuracy: 0.6494 - val_loss: 0.5887\n",
            "Epoch 246/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6706 - loss: 0.5872 - val_accuracy: 0.6494 - val_loss: 0.5883\n",
            "Epoch 247/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6709 - loss: 0.5881 - val_accuracy: 0.6494 - val_loss: 0.5879\n",
            "Epoch 248/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7358 - loss: 0.5513 - val_accuracy: 0.6558 - val_loss: 0.5875\n",
            "Epoch 249/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6786 - loss: 0.5708 - val_accuracy: 0.6558 - val_loss: 0.5871\n",
            "Epoch 250/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6828 - loss: 0.5621 - val_accuracy: 0.6558 - val_loss: 0.5867\n",
            "Epoch 251/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6791 - loss: 0.5658 - val_accuracy: 0.6558 - val_loss: 0.5863\n",
            "Epoch 252/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6880 - loss: 0.5789 - val_accuracy: 0.6558 - val_loss: 0.5859\n",
            "Epoch 253/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6888 - loss: 0.5704 - val_accuracy: 0.6558 - val_loss: 0.5856\n",
            "Epoch 254/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7221 - loss: 0.5458 - val_accuracy: 0.6558 - val_loss: 0.5852\n",
            "Epoch 255/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7092 - loss: 0.5598 - val_accuracy: 0.6623 - val_loss: 0.5848\n",
            "Epoch 256/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6907 - loss: 0.5571 - val_accuracy: 0.6623 - val_loss: 0.5844\n",
            "Epoch 257/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6756 - loss: 0.5719 - val_accuracy: 0.6623 - val_loss: 0.5840\n",
            "Epoch 258/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7135 - loss: 0.5503 - val_accuracy: 0.6623 - val_loss: 0.5837\n",
            "Epoch 259/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7013 - loss: 0.5546 - val_accuracy: 0.6688 - val_loss: 0.5833\n",
            "Epoch 260/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7192 - loss: 0.5574 - val_accuracy: 0.6753 - val_loss: 0.5829\n",
            "Epoch 261/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6470 - loss: 0.5923 - val_accuracy: 0.6753 - val_loss: 0.5825\n",
            "Epoch 262/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6820 - loss: 0.5810 - val_accuracy: 0.6753 - val_loss: 0.5821\n",
            "Epoch 263/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6737 - loss: 0.5796 - val_accuracy: 0.6753 - val_loss: 0.5818\n",
            "Epoch 264/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7054 - loss: 0.5672 - val_accuracy: 0.6753 - val_loss: 0.5814\n",
            "Epoch 265/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6819 - loss: 0.5843 - val_accuracy: 0.6753 - val_loss: 0.5810\n",
            "Epoch 266/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6997 - loss: 0.5626 - val_accuracy: 0.6753 - val_loss: 0.5807\n",
            "Epoch 267/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7014 - loss: 0.5588 - val_accuracy: 0.6753 - val_loss: 0.5803\n",
            "Epoch 268/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7111 - loss: 0.5624 - val_accuracy: 0.6753 - val_loss: 0.5799\n",
            "Epoch 269/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7069 - loss: 0.5553 - val_accuracy: 0.6688 - val_loss: 0.5795\n",
            "Epoch 270/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6893 - loss: 0.5715 - val_accuracy: 0.6688 - val_loss: 0.5792\n",
            "Epoch 271/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7074 - loss: 0.5632 - val_accuracy: 0.6688 - val_loss: 0.5788\n",
            "Epoch 272/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7292 - loss: 0.5544 - val_accuracy: 0.6753 - val_loss: 0.5785\n",
            "Epoch 273/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6875 - loss: 0.5507 - val_accuracy: 0.6753 - val_loss: 0.5781\n",
            "Epoch 274/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7195 - loss: 0.5526 - val_accuracy: 0.6883 - val_loss: 0.5777\n",
            "Epoch 275/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7226 - loss: 0.5655 - val_accuracy: 0.6883 - val_loss: 0.5774\n",
            "Epoch 276/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7215 - loss: 0.5476 - val_accuracy: 0.6883 - val_loss: 0.5770\n",
            "Epoch 277/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7298 - loss: 0.5568 - val_accuracy: 0.6883 - val_loss: 0.5766\n",
            "Epoch 278/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6776 - loss: 0.5741 - val_accuracy: 0.6883 - val_loss: 0.5763\n",
            "Epoch 279/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7053 - loss: 0.5601 - val_accuracy: 0.6883 - val_loss: 0.5759\n",
            "Epoch 280/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6980 - loss: 0.5624 - val_accuracy: 0.6883 - val_loss: 0.5756\n",
            "Epoch 281/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7069 - loss: 0.5522 - val_accuracy: 0.6883 - val_loss: 0.5752\n",
            "Epoch 282/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7455 - loss: 0.5352 - val_accuracy: 0.6883 - val_loss: 0.5748\n",
            "Epoch 283/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6848 - loss: 0.5813 - val_accuracy: 0.6883 - val_loss: 0.5745\n",
            "Epoch 284/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7178 - loss: 0.5456 - val_accuracy: 0.6883 - val_loss: 0.5742\n",
            "Epoch 285/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7174 - loss: 0.5455 - val_accuracy: 0.6883 - val_loss: 0.5738\n",
            "Epoch 286/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6815 - loss: 0.5774 - val_accuracy: 0.6883 - val_loss: 0.5734\n",
            "Epoch 287/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6802 - loss: 0.5773 - val_accuracy: 0.6883 - val_loss: 0.5731\n",
            "Epoch 288/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6933 - loss: 0.5632 - val_accuracy: 0.6948 - val_loss: 0.5727\n",
            "Epoch 289/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7637 - loss: 0.5206 - val_accuracy: 0.6883 - val_loss: 0.5724\n",
            "Epoch 290/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7520 - loss: 0.5355 - val_accuracy: 0.6883 - val_loss: 0.5721\n",
            "Epoch 291/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7200 - loss: 0.5550 - val_accuracy: 0.6883 - val_loss: 0.5717\n",
            "Epoch 292/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7309 - loss: 0.5510 - val_accuracy: 0.7013 - val_loss: 0.5714\n",
            "Epoch 293/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7026 - loss: 0.5635 - val_accuracy: 0.7013 - val_loss: 0.5711\n",
            "Epoch 294/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7278 - loss: 0.5285 - val_accuracy: 0.7013 - val_loss: 0.5707\n",
            "Epoch 295/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6885 - loss: 0.5703 - val_accuracy: 0.7013 - val_loss: 0.5704\n",
            "Epoch 296/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6909 - loss: 0.5734 - val_accuracy: 0.7013 - val_loss: 0.5700\n",
            "Epoch 297/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7337 - loss: 0.5318 - val_accuracy: 0.7013 - val_loss: 0.5697\n",
            "Epoch 298/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7185 - loss: 0.5468 - val_accuracy: 0.7013 - val_loss: 0.5694\n",
            "Epoch 299/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6918 - loss: 0.5554 - val_accuracy: 0.7013 - val_loss: 0.5690\n",
            "Epoch 300/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7370 - loss: 0.5307 - val_accuracy: 0.7013 - val_loss: 0.5687\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6943 - loss: 0.5765\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Test Accuracy: 0.7013\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Non-Diabetic       0.70      0.95      0.80        99\n",
            "    Diabetic       0.74      0.25      0.38        55\n",
            "\n",
            "    accuracy                           0.70       154\n",
            "   macro avg       0.72      0.60      0.59       154\n",
            "weighted avg       0.71      0.70      0.65       154\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x797dde99b6a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
            "Prediction: Non-Diabetic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ClpKc_1gUIe8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}